{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_with_local_attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRooPBDZryc_",
        "colab_type": "text"
      },
      "source": [
        "Code to replicate sequence-to-sequence architecture, with Luong local attention (monotonic and predictive). If you find any issues with this implementation, please raise an issue. Thanks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbjOYeDG19w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://arxiv.org/pdf/1508.04025.pdf\n",
        "# https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#a-family-of-attention-mechanisms\n",
        "# https://blog.floydhub.com/attention-mechanism/\n",
        "# https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C415mHjozxCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import re\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW7g1PkVTTTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrwzUsJuix3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75714d66-0503-477e-8d00-cc9a7e269f33"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9Ww8oigzSHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "b63b07de-eea4-44f8-afa7-c8ee2ed0b9b6"
      },
      "source": [
        "!python -m spacy download de_core_news_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=6c40453e33a2efc01f76f767bccad1445fe9e746b0b205df1fdc98fd494f4639\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g8xtu9sp/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p_g0Hcg1e5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "9eb1b307-cbfc-4fcd-d997-19e818dec0da"
      },
      "source": [
        "# https://stackoverflow.com/questions/56927602/unable-to-load-the-spacy-model-en-core-web-lg-on-google-colab\n",
        "# https://spacy.io/usage/models\n",
        "\n",
        "!pip install de_core_news_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: de_core_news_sm in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (49.1.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (0.7.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm) (1.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5tUOzUd4wJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import de_core_news_sm\n",
        "spacy_de = de_core_news_sm.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_eVHQdG4YlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "e137f637-bcf1-443b-8547-6892f2a8c620"
      },
      "source": [
        "!pip install en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (0.7.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (49.1.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq5MgTZ45jUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import en_core_web_sm\n",
        "spacy_en = en_core_web_sm.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoGnCYb55nmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = re.compile('(<url>.*</url>)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahkwwkBG1mkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84DpBWNP1sbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "DE = data.Field(tokenize=tokenize_de, init_token='<sos>', eos_token='<eos>')\n",
        "EN = data.Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWfdpGdh6rJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "042ce01f-ce1d-4b76-f3ed-3ee406651d27"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/data/data/translation/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VHAElbx1uFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "7a5e5f32-f750-4052-d646-5bbf4508300e"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.Multi30k.splits(exts=('.de', '.en'), fields=(DE, EN))\n",
        "print('Loaded data...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 823kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 221kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 209kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRR9469r7U7N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "85e3551e-7a54-429b-cb49-a55f70bda383"
      },
      "source": [
        "print(train_data.fields)\n",
        "print(len(train_data))\n",
        "print(len(valid_data))\n",
        "print(vars(train_data[0]))\n",
        "print(vars(train_data[100]))\n",
        "print(vars(valid_data[100]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'src': <torchtext.data.field.Field object at 0x7f1de4ab3c88>, 'trg': <torchtext.data.field.Field object at 0x7f1de7eea9b0>}\n",
            "29000\n",
            "1014\n",
            "{'src': ['Zwei', 'junge', 'weiße', 'Männer', 'sind', 'im', 'Freien', 'in', 'der', 'Nähe', 'vieler', 'Büsche', '.'], 'trg': ['Two', 'young', ',', 'White', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n",
            "{'src': ['Männliches', 'Kleinkind', 'in', 'einem', 'roten', 'Hut', ',', 'das', 'sich', 'an', 'einem', 'Geländer', 'festhält', '.'], 'trg': ['Toddler', 'boy', 'in', 'a', 'red', 'hat', 'holding', 'on', 'to', 'some', 'railings', '.']}\n",
            "{'src': ['Ein', 'älterer', ',', 'übergewichtiger', 'Mann', 'wendet', 'einen', 'Pfannkuchen', ',', 'während', 'er', 'Frühstück', 'macht', '.'], 'trg': ['An', 'older', ',', 'overweight', 'man', 'flips', 'a', 'pancake', 'while', 'making', 'breakfast', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6XDPfZkB6p4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set source and target language\n",
        "DE.build_vocab(train_data.src, min_freq=3)\n",
        "EN.build_vocab(train_data.trg, min_freq=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FwAMWsnCOs0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "5ab6cef6-2f32-4bc2-ff01-358a6b44d0c7"
      },
      "source": [
        "train_iter, valid_iter = data.BucketIterator.splits((train_data, valid_data), batch_size=32, device=device)\n",
        "\n",
        "print(DE.vocab.freqs.most_common(10))\n",
        "print(len(DE.vocab))\n",
        "print(EN.vocab.freqs.most_common(10))\n",
        "print(len(EN.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('.', 28821), ('Ein', 13904), ('einem', 13697), ('in', 11830), (',', 8938), ('und', 8925), ('mit', 8838), ('auf', 8686), ('Mann', 7805), ('einer', 6750)]\n",
            "5500\n",
            "[('a', 31707), ('.', 27623), ('A', 17458), ('in', 14847), ('the', 9923), ('on', 8019), ('is', 7524), ('and', 7378), ('man', 7359), ('of', 6871)]\n",
            "4727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_4fR3w0HAkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size, device):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.to(self.device)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        # input is of shape [1, batch_size]\n",
        "        # embedded is of shape [1, batch_size, embedding_size]\n",
        "\n",
        "        input = input.to(self.device)\n",
        "\n",
        "        embedded = self.embed(input)\n",
        "\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "\n",
        "        # output shape is [1, batch_size, hidden_dim]\n",
        "        # hidden shape is [num_layers, batch_size, hidden_dim]\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(1, batch_size, self.hidden_size, device=device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kmQvH4PIjL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionDecoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size, n_dropout, attend_type, local, D, device):\n",
        "        super(AttentionDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n_dropout = n_dropout\n",
        "        self.attend_type = attend_type\n",
        "        self.local = local\n",
        "        self.D = D\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.gru = nn.GRU(self.embedding_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.n_dropout)\n",
        "\n",
        "        self.align = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.align_gen = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.V = nn.Parameter(torch.rand(hidden_size))\n",
        "        self.Wp = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.Vp = nn.Parameter(torch.rand(hidden_size))\n",
        "\n",
        "        self.appl_context = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "        self.device = device\n",
        "        self.to(self.device)\n",
        "\n",
        "    def attend_concat(self, enc_outputs, dec_output):\n",
        "        # dec_output:  [1, batch_size, hidden_dim]\n",
        "        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n",
        "\n",
        "        batch_size = dec_output.size(1)\n",
        "        sequence_len = enc_outputs.size(0)\n",
        "\n",
        "        dec_output = dec_output.repeat(sequence_len, 1, 1)\n",
        "        #dec_output:  [sequence_len, batch_size, hidden_dim]\n",
        "\n",
        "        attn_in = torch.cat((enc_outputs, dec_output), dim=-1)\n",
        "        # combined enc_outputs and hidden:  [sequence_len, batch_size, hidden_dim * 2]\n",
        "\n",
        "        aligned = self.align(attn_in)\n",
        "        aligned = torch.tanh(aligned)\n",
        "    \n",
        "        aligned = aligned.permute(1, 2, 0)\n",
        "        #aligned = [batch size, hidden_dim, sequence_len]\n",
        "        \n",
        "        #v = [hidden_dim]\n",
        "        v = self.V.repeat(batch_size, 1).unsqueeze(1)\n",
        "        #v = [batch size, 1, hidden_dim]\n",
        "\n",
        "        attention = torch.bmm(v, aligned).squeeze(1)\n",
        "        #attention = [batch size, sequence_len]\n",
        "\n",
        "        return attention\n",
        "\n",
        "    def attend_dot(self, enc_outputs, dec_output):\n",
        "        # dec_output:  [1, batch_size, hidden_dim]\n",
        "        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n",
        "        \n",
        "        dec_output = dec_output.permute(1, 0, 2)\n",
        "        # dec_output:  [batch_size, 1, hidden_dim]\n",
        "\n",
        "        enc_outputs = enc_outputs.permute(1, 2, 0)\n",
        "        # enc_outputs is of shape [batch_size, hidden_dim, sequence_len]\n",
        "        \n",
        "        attention = torch.bmm(dec_output, enc_outputs)\n",
        "        # weighted = [batch_size, 1, sequence_len]\n",
        "\n",
        "        attention = attention.squeeze(1)\n",
        "        # attention is of shape [batch_size, sequence_len]\n",
        "\n",
        "        return attention\n",
        "\n",
        "    def attend_general(self, enc_outputs, dec_output):\n",
        "        # dec_output:  [1, batch_size, hidden_dim]\n",
        "        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n",
        "\n",
        "        enc_outputs = self.align_gen(enc_outputs)\n",
        "        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n",
        "\n",
        "        dec_output = dec_output.permute(1, 0, 2)\n",
        "        enc_outputs = enc_outputs.permute(1, 2, 0)\n",
        "        attention = torch.bmm(dec_output, enc_outputs)\n",
        "        attention = attention.squeeze(1)\n",
        "\n",
        "        return attention\n",
        "\n",
        "    def forward(self, input, hidden, enc_outputs, p_t):\n",
        "        # input is of shape [batch_size]\n",
        "        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n",
        "        # hidden is of shape [1, batch_size, hidden_dim]\n",
        "\n",
        "        # Decoder\n",
        "\n",
        "        batch_size = hidden.size(1)\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        # now, input shape is [1, batch_size]\n",
        "\n",
        "        input = input.to(self.device)\n",
        "\n",
        "        embedded = self.embed(input)\n",
        "        embedded = self.dropout(embedded)\n",
        "        # embedded is of shape [1, batch_size, embedding_dim]\n",
        "\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        #output:  [1, batch_size, hidden_dim]\n",
        "\n",
        "        # Attention\n",
        "\n",
        "        sequence_len = enc_outputs.size(0)\n",
        "\n",
        "        # Monotonic alignment (local-m)\n",
        "        if self.local == 'm':\n",
        "            if p_t > sequence_len:\n",
        "                p_t = sequence_len\n",
        "\n",
        "            win_min = max(0, p_t - self.D)\n",
        "            win_max = min(sequence_len, p_t + self.D + 1)\n",
        "\n",
        "            enc_outputs = enc_outputs[win_min: win_max]\n",
        "            # enc_outputs is of shape [local_context_window (2D+1), batch_size, hidden_dim]\n",
        "\n",
        "        if self.attend_type == 'concat':\n",
        "            attention = self.attend_concat(enc_outputs, output)\n",
        "        elif self.attend_type == 'dot':\n",
        "            attention = self.attend_dot(enc_outputs, output)\n",
        "        elif self.attend_type == 'general':\n",
        "            attention = self.attend_general(enc_outputs, output)\n",
        "\n",
        "        alphas = F.softmax(attention, dim=1)\n",
        "        #alphas = [batch_size, sequence_len]\n",
        "\n",
        "        alphas = alphas.unsqueeze(1)\n",
        "        #alphas =  [batch_size, 1, sequence_len]\n",
        "\n",
        "        # Predictive alignment (local-p)\n",
        "        if self.local == 'p':\n",
        "            local_p = torch.tanh(self.Wp(output))\n",
        "            # local_p = [1, batch_size, hidden_size]\n",
        "            # b×m×p\n",
        "            local_p = local_p.permute(1, 2, 0)\n",
        "            # local_p = [batch_size, hidden_size, 1]\n",
        "\n",
        "            # Vp = [hidden_size]\n",
        "            vp = self.Vp.repeat(batch_size, 1).unsqueeze(1)\n",
        "            # Vp = [batch_size, 1, hidden_size]\n",
        "            # b×n×m\n",
        "            # Vp = [batch_size, 1, hidden_size]\n",
        "\n",
        "            # b×n×p\n",
        "            p_t = sequence_len * torch.sigmoid(torch.bmm(vp, local_p))\n",
        "            # p_t = [batch_size, 1, 1]\n",
        "\n",
        "            s = torch.arange(0, sequence_len, device=self.device, requires_grad=False)\n",
        "            # s = [1, sequence_len]\n",
        "            s = s.repeat(batch_size, 1).unsqueeze(1)\n",
        "            # s = [batch_size, 1, sequence_len]\n",
        "\n",
        "            expression = -(s - p_t) / (self.D**2 / 2)\n",
        "            expression = torch.exp(expression)\n",
        "            # expression = [batch_size, 1, sequence_len]\n",
        "\n",
        "            #alphas =  [batch_size, 1, sequence_len]\n",
        "\n",
        "            alphas = alphas * expression\n",
        "            #alphas =  [batch_size, 1, sequence_len]\n",
        "\n",
        "        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n",
        "        enc_outputs = enc_outputs.permute(1, 0, 2)\n",
        "        #enc_outputs = [batch_size, sequence_len, hidden_dim]\n",
        "\n",
        "        context = torch.bmm(alphas, enc_outputs)\n",
        "        #weighted = [batch_size, 1, hidden_dim]\n",
        "        \n",
        "        context = context.permute(1, 0, 2)\n",
        "        #context: [1, batch_size, hidden_dim]\n",
        "\n",
        "        output = torch.cat((output, context), dim=-1)\n",
        "        #output:  [1, batch_size, hidden_dim * 2]\n",
        "\n",
        "        output = self.appl_context(output)\n",
        "        output = torch.tanh(output)\n",
        "\n",
        "        output = self.out(output.squeeze(0))\n",
        "        #output:  [1, batch_size, vocab_size]\n",
        "\n",
        "        output = self.logsoftmax(output)\n",
        "\n",
        "        return output, hidden, alphas\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lPdNYu4wbAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(enc)\n",
        "#print(dec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYqrDNmxV7Nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "2de74f20-287f-4f2b-d48a-4cc04203ef00"
      },
      "source": [
        "vocab_size_src = len(DE.vocab)\n",
        "vocab_size_trg = len(EN.vocab)\n",
        "\n",
        "embedding_size = 300\n",
        "hidden_size = 128\n",
        "n_dropout = 0.1\n",
        "\n",
        "# attention type: concat, dot, attend\n",
        "attend_type = 'concat'\n",
        "# m - monotonic local attention, p - predictive local attention\n",
        "local = 'm'\n",
        "# monotonic local attention window\n",
        "D = 2\n",
        "\n",
        "enc = EncoderRNN(vocab_size_src, embedding_size, hidden_size, device)\n",
        "dec = AttentionDecoderRNN(vocab_size_trg, embedding_size, hidden_size, n_dropout, attend_type, local, D, device)\n",
        "\n",
        "enc_optim = optim.Adam(enc.parameters())\n",
        "dec_optim = optim.Adam(dec.parameters())\n",
        "    \n",
        "pad_idx = EN.vocab.stoi['<pad>']\n",
        "print('Pad index: ', pad_idx)\n",
        "criterion = nn.NLLLoss(ignore_index=pad_idx)\n",
        "\n",
        "epochs = 20\n",
        "clip = 10\n",
        "\n",
        "epoch_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in train_iter:\n",
        "        hidden = enc.init_hidden(batch.src.size(1))\n",
        "\n",
        "        max_len_enc = batch.src.size(0)\n",
        "\n",
        "        enc_outputs, hidden = enc(batch.src, hidden)\n",
        "\n",
        "        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n",
        "\n",
        "        # store outputs\n",
        "        max_len_dec = batch.trg.size(0)\n",
        "\n",
        "        outputs = torch.zeros(max_len_dec, batch.trg.size(1), vocab_size_trg, device=device)\n",
        "        input = batch.trg[0]\n",
        "        \n",
        "        for i in range(1, max_len_dec):\n",
        "            output, hidden, alphas = dec(input, hidden, enc_outputs, i)\n",
        "            outputs[i] = output\n",
        "            input = batch.trg[i]\n",
        "\n",
        "        enc_optim.zero_grad()\n",
        "        dec_optim.zero_grad()\n",
        "\n",
        "        target = torch.tensor(batch.trg[1:], device=device)\n",
        "        loss = criterion(outputs[1:].view(-1, outputs.shape[2]), target.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(enc.parameters(), clip)\n",
        "        nn.utils.clip_grad_norm_(dec.parameters(), clip)\n",
        "\n",
        "        enc_optim.step()\n",
        "        dec_optim.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        print('\\rEpoch {} : Loss {:.3f}'.format(epoch, epoch_loss / len(batch)), end=\"\")\n",
        "\n",
        "    print('\\rEpoch {} : Loss {:.3f}'.format(epoch, epoch_loss / len(train_iter)))\n",
        "\n",
        "    epoch_losses.append(epoch_loss / len(train_iter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad index:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 : Loss 3.631\n",
            "Epoch 1 : Loss 2.539\n",
            "Epoch 2 : Loss 2.154\n",
            "Epoch 3 : Loss 1.915\n",
            "Epoch 4 : Loss 1.744\n",
            "Epoch 5 : Loss 1.610\n",
            "Epoch 6 : Loss 1.501\n",
            "Epoch 7 : Loss 1.408\n",
            "Epoch 8 : Loss 1.327\n",
            "Epoch 9 : Loss 1.255\n",
            "Epoch 10 : Loss 1.192\n",
            "Epoch 11 : Loss 1.135\n",
            "Epoch 12 : Loss 1.082\n",
            "Epoch 13 : Loss 1.036\n",
            "Epoch 14 : Loss 0.992\n",
            "Epoch 15 : Loss 0.954\n",
            "Epoch 16 : Loss 0.917\n",
            "Epoch 17 : Loss 0.882\n",
            "Epoch 18 : Loss 0.852\n",
            "Epoch 19 : Loss 0.825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJzP-aiMpj84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "a957508b-69f5-4c14-8960-b1a6ffce49bb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch_losses)\n",
        "plt.title(\"Training loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiXYRMKkqiyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_attention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(np.array(attentions))\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ6RHiXNPeEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "15158f8d-7111-4400-8d52-cca0b9774715"
      },
      "source": [
        "#### Predictive local attention\n",
        "\n",
        "sos_idx = EN.vocab.stoi['<sos>']\n",
        "eos_idx = EN.vocab.stoi['<eos>']\n",
        "\n",
        "batch = next(iter(valid_iter))\n",
        "\n",
        "for i in range(5):\n",
        "    with torch.no_grad():\n",
        "        encoder_input = batch.src[:, i].unsqueeze(1)\n",
        "        hidden = enc.init_hidden(1)\n",
        "\n",
        "        encoded = []\n",
        "        for ip in encoder_input:\n",
        "            encoded.append(DE.vocab.itos[ip.item()])\n",
        "\n",
        "        enc_outputs, hidden = enc(encoder_input, hidden)\n",
        "\n",
        "        max_len_enc = batch.src.size(0)\n",
        "        max_len_dec = batch.trg.size(0)\n",
        "        decoder_input = torch.tensor([sos_idx], device=device)\n",
        "        decoder_attentions = torch.zeros(max_len_dec*2, max_len_enc)\n",
        "\n",
        "        decoded = []\n",
        "        decoded.append(EN.vocab.itos[sos_idx])\n",
        "\n",
        "        true = [EN.vocab.itos[w] for w in batch.trg[:, i].unsqueeze(1)]\n",
        "\n",
        "        k = 0\n",
        "        while True:\n",
        "            output, hidden, alphas = dec(decoder_input, hidden, enc_outputs, k)\n",
        "            topv, topi = output.topk(1)\n",
        "            topi = topi.squeeze(1)\n",
        "            decoder_input = topi.detach()\n",
        "\n",
        "            decoder_attentions[k] = alphas\n",
        "            k += 1\n",
        "            \n",
        "            decoded.append(EN.vocab.itos[decoder_input.item()])\n",
        "            if decoder_input.item() == eos_idx:\n",
        "                break\n",
        "\n",
        "        print(encoded)\n",
        "        print(decoded)\n",
        "        print(true)\n",
        "        print()\n",
        "\n",
        "        #show_attention(encoded, decoded, decoder_attentions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<sos>', 'Ein', 'Kind', 'sitzt', 'auf', 'einer', '<unk>', '.', '<eos>']\n",
            "['<sos>', 'A', 'child', 'sitting', 'on', 'a', 'red', 'bench', '.', '<eos>']\n",
            "['<sos>', 'A', 'child', 'sitting', 'on', 'a', 'rock', 'formation', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "['<sos>', 'Zwei', 'Frauen', 'lächeln', 'bei', 'einer', 'Veranstaltung', '.', '<eos>']\n",
            "['<sos>', 'A', 'woman', 'is', 'smiling', 'at', 'a', 'restaurant', '.', '<eos>']\n",
            "['<sos>', 'Two', 'women', 'are', 'smiling', 'at', 'an', 'event', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "['<sos>', 'Zwei', 'Pudel', 'rennen', 'durch', 'den', 'Schnee', '.', '<eos>']\n",
            "['<sos>', 'A', 'black', 'poodle', 'runs', 'through', 'the', 'snow', '.', '<eos>']\n",
            "['<sos>', 'Two', 'poodles', 'are', 'running', 'through', 'the', 'snow', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "['<sos>', '<unk>', '<unk>', 'tagsüber', 'ihre', '<unk>', '.', '<eos>', '<pad>']\n",
            "['<sos>', 'A', '<unk>', '<unk>', 'is', 'showing', 'her', 'brother', 'as', 'he', 'reaches', 'his', '<unk>', '.', '<eos>']\n",
            "['<sos>', '<unk>', 'are', 'performing', 'their', '<unk>', 'during', 'the', 'day', '.', '<eos>', '<pad>', '<pad>']\n",
            "\n",
            "['<sos>', 'Drei', 'Hunde', 'spielen', 'im', 'Wasser', '.', '<eos>', '<pad>']\n",
            "['<sos>', 'Three', 'dogs', 'are', 'playing', 'in', 'the', 'water', '.', '<eos>']\n",
            "['<sos>', 'Three', 'dogs', 'are', 'playing', 'in', 'the', 'water', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls0tkuHza2di",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "c1bfa486-cffc-4357-dce1-10376241da4b"
      },
      "source": [
        "#### Monotonic local attention\n",
        "\n",
        "sos_idx = EN.vocab.stoi['<sos>']\n",
        "eos_idx = EN.vocab.stoi['<eos>']\n",
        "\n",
        "batch = next(iter(valid_iter))\n",
        "\n",
        "for i in range(5):\n",
        "    with torch.no_grad():\n",
        "        encoder_input = batch.src[:, i].unsqueeze(1)\n",
        "        hidden = enc.init_hidden(1)\n",
        "\n",
        "        encoded = []\n",
        "        for ip in encoder_input:\n",
        "            encoded.append(DE.vocab.itos[ip.item()])\n",
        "\n",
        "        enc_outputs, hidden = enc(encoder_input, hidden)\n",
        "\n",
        "        max_len_enc = batch.src.size(0)\n",
        "        max_len_dec = batch.trg.size(0)\n",
        "        decoder_input = torch.tensor([sos_idx], device=device)\n",
        "        #decoder_attentions = torch.zeros(max_len_dec*2, max_len_enc)\n",
        "\n",
        "        decoded = []\n",
        "        decoded.append(EN.vocab.itos[sos_idx])\n",
        "\n",
        "        true = [EN.vocab.itos[w] for w in batch.trg[:, i].unsqueeze(1)]\n",
        "\n",
        "        k = 0\n",
        "        while True:\n",
        "            output, hidden, alphas = dec(decoder_input, hidden, enc_outputs, k)\n",
        "            topv, topi = output.topk(1)\n",
        "            topi = topi.squeeze(1)\n",
        "            decoder_input = topi.detach()\n",
        "\n",
        "            #decoder_attentions[k, D-k:D+k+1] = alphas\n",
        "            k += 1\n",
        "            \n",
        "            decoded.append(EN.vocab.itos[decoder_input.item()])\n",
        "            if decoder_input.item() == eos_idx:\n",
        "                break\n",
        "\n",
        "        print(encoded)\n",
        "        print(decoded)\n",
        "        print(true)\n",
        "        print()\n",
        "\n",
        "        #show_attention(encoded, decoded, decoder_attentions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<sos>', 'Ein', 'Kind', 'sitzt', 'auf', 'einer', '<unk>', '.', '<eos>']\n",
            "['<sos>', 'A', 'child', 'sits', 'on', 'a', 'cement', 'track', '.', '<eos>']\n",
            "['<sos>', 'A', 'child', 'sitting', 'on', 'a', 'rock', 'formation', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "['<sos>', 'Zwei', 'Frauen', 'lächeln', 'bei', 'einer', 'Veranstaltung', '.', '<eos>']\n",
            "['<sos>', 'Two', 'women', 'are', 'smiling', 'at', 'an', 'event', 'at', 'an', 'event', '.', '<eos>']\n",
            "['<sos>', 'Two', 'women', 'are', 'smiling', 'at', 'an', 'event', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "['<sos>', 'Zwei', 'Pudel', 'rennen', 'durch', 'den', 'Schnee', '.', '<eos>']\n",
            "['<sos>', 'Two', 'poodles', 'running', 'through', 'the', 'snow', '.', '<eos>']\n",
            "['<sos>', 'Two', 'poodles', 'are', 'running', 'through', 'the', 'snow', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
            "\n",
            "['<sos>', '<unk>', '<unk>', 'tagsüber', 'ihre', '<unk>', '.', '<eos>', '<pad>']\n",
            "['<sos>', '<unk>', '<unk>', 'dancers', 'their', 'fellow', '<unk>', 'their', '<unk>', '.', '<eos>']\n",
            "['<sos>', '<unk>', 'are', 'performing', 'their', '<unk>', 'during', 'the', 'day', '.', '<eos>', '<pad>', '<pad>']\n",
            "\n",
            "['<sos>', 'Drei', 'Hunde', 'spielen', 'im', 'Wasser', '.', '<eos>', '<pad>']\n",
            "['<sos>', 'Three', 'dogs', 'are', 'playing', 'in', 'the', 'water', '.', '<eos>']\n",
            "['<sos>', 'Three', 'dogs', 'are', 'playing', 'in', 'the', 'water', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}