{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq_with_luong_attention.ipynb","provenance":[{"file_id":"1-nlMBlkGZ-xxwdOJqfb1Tp3-KLZaWta8","timestamp":1594266839735},{"file_id":"1iegejog2UrS2-vJV4QxbgZIzAUiG4qXY","timestamp":1593786333308},{"file_id":"12YLjnXeJJ40owGz1RJNbyR6Lm-cqFfFZ","timestamp":1593669730170}],"collapsed_sections":[],"authorship_tag":"ABX9TyPux5rFynbLpZieA+Te8KjE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yRooPBDZryc_","colab_type":"text"},"source":["Code to replicate sequence-to-sequence architecture, with Luong global attention"]},{"cell_type":"code","metadata":{"id":"QbjOYeDG19w-","colab_type":"code","colab":{}},"source":["# https://arxiv.org/pdf/1508.04025.pdf\n","# https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#a-family-of-attention-mechanisms\n","# https://blog.floydhub.com/attention-mechanism/\n","# https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C415mHjozxCJ","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchtext import data\n","from torchtext import datasets\n","import re\n","import spacy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LW7g1PkVTTTC","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrwzUsJuix3G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594359216348,"user_tz":-330,"elapsed":2096,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"a70b0306-5039-46df-b167-3cc19d72fea0"},"source":["device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"M9Ww8oigzSHo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":462},"executionInfo":{"status":"ok","timestamp":1594359223031,"user_tz":-330,"elapsed":6636,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"1d299070-69a7-4df0-ec1c-788946262a04"},"source":["!python -m spacy download de_core_news_sm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (47.3.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.9)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9p_g0Hcg1e5R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"ok","timestamp":1594359227219,"user_tz":-330,"elapsed":9736,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"dbc0c5fc-84bc-467c-a67f-cc94dc02714c"},"source":["# https://stackoverflow.com/questions/56927602/unable-to-load-the-spacy-model-en-core-web-lg-on-google-colab\n","# https://spacy.io/usage/models\n","\n","!pip install de_core_news_sm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: de_core_news_sm in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm) (2.2.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (0.7.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (4.41.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (2.0.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.18.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (7.4.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (47.3.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (3.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (0.4.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm) (2.23.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm) (1.6.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e5tUOzUd4wJX","colab_type":"code","colab":{}},"source":["import de_core_news_sm\n","spacy_de = de_core_news_sm.load()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_eVHQdG4YlM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"ok","timestamp":1594359231876,"user_tz":-330,"elapsed":12708,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"05af51b9-6f25-44c8-c36a-602f7b7b4435"},"source":["!pip install en_core_web_sm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm) (2.2.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (47.3.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (0.7.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.0.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (0.4.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (4.41.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (3.0.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (1.18.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (2.0.3)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm) (7.4.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm) (1.6.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm) (2020.6.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sq5MgTZ45jUD","colab_type":"code","colab":{}},"source":["import en_core_web_sm\n","spacy_en = en_core_web_sm.load()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GoGnCYb55nmZ","colab_type":"code","colab":{}},"source":["url = re.compile('(<url>.*</url>)')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahkwwkBG1mkm","colab_type":"code","colab":{}},"source":["def tokenize_de(text):\n","    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n","\n","def tokenize_en(text):\n","    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"84DpBWNP1sbi","colab_type":"code","colab":{}},"source":["from torchtext.data.utils import get_tokenizer\n","\n","DE = data.Field(tokenize=tokenize_de, init_token='<sos>', eos_token='<eos>')\n","EN = data.Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWfdpGdh6rJc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594359232422,"user_tz":-330,"elapsed":9118,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"629a1aa6-d447-4dc8-d604-2b17b0d1b31e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = '/content/drive/My Drive/data/data/translation/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2VHAElbx1uFH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594359236237,"user_tz":-330,"elapsed":11643,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"f5e1a36a-cef6-47cd-c64d-68f015423be6"},"source":["train_data, valid_data, test_data = datasets.Multi30k.splits(exts=('.de', '.en'), fields=(DE, EN))\n","print('Loaded data...')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded data...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oRR9469r7U7N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":148},"executionInfo":{"status":"ok","timestamp":1594359236249,"user_tz":-330,"elapsed":10340,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"898a2aae-0c37-4e09-efd4-f82dba588882"},"source":["print(train_data.fields)\n","print(len(train_data))\n","print(len(valid_data))\n","print(vars(train_data[0]))\n","print(vars(train_data[100]))\n","print(vars(valid_data[100]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'src': <torchtext.data.field.Field object at 0x7f5e16220ba8>, 'trg': <torchtext.data.field.Field object at 0x7f5e16220c18>}\n","29000\n","1014\n","{'src': ['Zwei', 'junge', 'weiÃŸe', 'MÃ¤nner', 'sind', 'im', 'Freien', 'in', 'der', 'NÃ¤he', 'vieler', 'BÃ¼sche', '.'], 'trg': ['Two', 'young', ',', 'White', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n","{'src': ['MÃ¤nnliches', 'Kleinkind', 'in', 'einem', 'roten', 'Hut', ',', 'das', 'sich', 'an', 'einem', 'GelÃ¤nder', 'festhÃ¤lt', '.'], 'trg': ['Toddler', 'boy', 'in', 'a', 'red', 'hat', 'holding', 'on', 'to', 'some', 'railings', '.']}\n","{'src': ['Ein', 'Ã¤lterer', ',', 'Ã¼bergewichtiger', 'Mann', 'wendet', 'einen', 'Pfannkuchen', ',', 'wÃ¤hrend', 'er', 'FrÃ¼hstÃ¼ck', 'macht', '.'], 'trg': ['An', 'older', ',', 'overweight', 'man', 'flips', 'a', 'pancake', 'while', 'making', 'breakfast', '.']}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P6XDPfZkB6p4","colab_type":"code","colab":{}},"source":["# set source and target language\n","DE.build_vocab(train_data.src, min_freq=3)\n","EN.build_vocab(train_data.trg, min_freq=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4FwAMWsnCOs0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1594359236260,"user_tz":-330,"elapsed":8456,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"a59bc18f-5009-4ae5-cb22-6bead6ca24af"},"source":["train_iter, valid_iter = data.BucketIterator.splits((train_data, valid_data), batch_size=32, device=device)\n","\n","print(DE.vocab.freqs.most_common(10))\n","print(len(DE.vocab))\n","print(EN.vocab.freqs.most_common(10))\n","print(len(EN.vocab))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('.', 28821), ('Ein', 13904), ('einem', 13697), ('in', 11830), (',', 8938), ('und', 8925), ('mit', 8838), ('auf', 8686), ('Mann', 7805), ('einer', 6750)]\n","5500\n","[('a', 31707), ('.', 27623), ('A', 17458), ('in', 14847), ('the', 9923), ('on', 8019), ('is', 7524), ('and', 7378), ('man', 7359), ('of', 6871)]\n","4727\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v_4fR3w0HAkr","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_size, hidden_size, device):\n","        super(EncoderRNN, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","\n","        self.embed = nn.Embedding(vocab_size, embedding_size)\n","        self.gru = nn.GRU(embedding_size, hidden_size)\n","\n","        self.device = device\n","        self.to(self.device)\n","        \n","    def forward(self, input, hidden):\n","        # input is of shape [1, batch_size]\n","        # embedded is of shape [1, batch_size, embedding_size]\n","\n","        input = input.to(self.device)\n","\n","        embedded = self.embed(input)\n","\n","        output, hidden = self.gru(embedded, hidden)\n","\n","        # output shape is [1, batch_size, hidden_dim]\n","        # hidden shape is [num_layers, batch_size, hidden_dim]\n","\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return torch.zeros(1, batch_size, self.hidden_size, device=device)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8kmQvH4PIjL4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594380704727,"user_tz":-330,"elapsed":1120,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}}},"source":["class AttentionDecoderRNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_size, hidden_size, n_dropout, attend_type, device):\n","        super(AttentionDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding_size = embedding_size\n","        self.n_dropout = n_dropout\n","        self.attend_type = attend_type\n","\n","        self.embed = nn.Embedding(vocab_size, embedding_size)\n","        self.gru = nn.GRU(self.embedding_size, self.hidden_size)\n","        self.dropout = nn.Dropout(self.n_dropout)\n","\n","        self.align = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.align_gen = nn.Linear(self.hidden_size, self.hidden_size)\n","        self.V = nn.Parameter(torch.rand(hidden_size))\n","\n","        self.appl_context = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.out = nn.Linear(hidden_size, vocab_size)\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","        \n","        self.device = device\n","        self.to(self.device)\n","\n","    def attend_concat(self, enc_outputs, dec_output):\n","        # dec_output:  [1, batch_size, hidden_dim]\n","        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n","\n","        batch_size = dec_output.size(1)\n","        sequence_len = enc_outputs.size(0)\n","\n","        dec_output = dec_output.repeat(sequence_len, 1, 1)\n","        #dec_output:  [sequence_len, batch_size, hidden_dim]\n","\n","        attn_in = torch.cat((enc_outputs, dec_output), dim=-1)\n","        # combined enc_outputs and hidden:  [sequence_len, batch_size, hidden_dim * 2]\n","\n","        aligned = self.align(attn_in)\n","        aligned = torch.tanh(aligned)\n","    \n","        aligned = aligned.permute(1, 2, 0)\n","        #aligned = [batch size, hidden_dim, sequence_len]\n","        \n","        #v = [hidden_dim]\n","        v = self.V.repeat(batch_size, 1).unsqueeze(1)\n","        #v = [batch size, 1, hidden_dim]\n","\n","        attention = torch.bmm(v, aligned).squeeze(1)\n","        #attention = [batch size, sequence_len]\n","\n","        return attention\n","\n","    def attend_dot(self, enc_outputs, dec_output):\n","        # dec_output:  [1, batch_size, hidden_dim]\n","        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n","        \n","        dec_output = dec_output.permute(1, 0, 2)\n","        # dec_output:  [batch_size, 1, hidden_dim]\n","\n","        enc_outputs = enc_outputs.permute(1, 2, 0)\n","        # enc_outputs is of shape [batch_size, hidden_dim, sequence_len]\n","        \n","        attention = torch.bmm(dec_output, enc_outputs)\n","        # weighted = [batch_size, 1, sequence_len]\n","\n","        attention = attention.squeeze(1)\n","        # attention is of shape [batch_size, sequence_len]\n","\n","        return attention\n","\n","    def attend_general(self, enc_outputs, dec_output):\n","        # dec_output:  [1, batch_size, hidden_dim]\n","        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n","\n","        enc_outputs = self.align_gen(enc_outputs)\n","        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n","\n","        dec_output = dec_output.permute(1, 0, 2)\n","        enc_outputs = enc_outputs.permute(1, 2, 0)\n","        attention = torch.bmm(dec_output, enc_outputs)\n","        attention = attention.squeeze(1)\n","\n","        return attention\n","\n","    def forward(self, input, hidden, enc_outputs):\n","        # input is of shape [batch_size]\n","        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n","        # hidden is of shape [1, batch_size, hidden_dim]\n","\n","        # Decoder\n","\n","        batch_size = hidden.size(1)\n","        \n","        input = input.unsqueeze(0)\n","        # now, input shape is [1, batch_size]\n","\n","        input = input.to(self.device)\n","\n","        embedded = self.embed(input)\n","        embedded = self.dropout(embedded)\n","        # embedded is of shape [1, batch_size, embedding_dim]\n","\n","        output, hidden = self.gru(embedded, hidden)\n","        #output:  [1, batch_size, hidden_dim]\n","\n","        # Attention\n","\n","        if self.attend_type == 'concat':\n","            attention = self.attend_concat(enc_outputs, output)\n","        elif self.attend_type == 'dot':\n","            attention = self.attend_dot(enc_outputs, output)\n","        elif self.attend_type == 'general':\n","            attention = self.attend_general(enc_outputs, output)\n","\n","        alphas = F.softmax(attention, dim=1)\n","        #alphas = [batch_size, sequence_len]\n","\n","        alphas = alphas.unsqueeze(1)\n","        #alphas =  [batch_size, 1, sequence_len]\n","\n","        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n","        enc_outputs = enc_outputs.permute(1, 0, 2)\n","        #enc_outputs = [batch_size, sequence_len, hidden_dim]\n","\n","        context = torch.bmm(alphas, enc_outputs)\n","        #weighted = [batch_size, 1, hidden_dim]\n","        \n","        context = context.permute(1, 0, 2)\n","        #context: [1, batch_size, hidden_dim]\n","\n","        output = torch.cat((output, context), dim=-1)\n","        #output:  [1, batch_size, hidden_dim * 2]\n","\n","        output = self.appl_context(output)\n","        output = torch.tanh(output)\n","\n","        output = self.out(output.squeeze(0))\n","        #output:  [1, batch_size, vocab_size]\n","\n","        output = self.logsoftmax(output)\n","\n","        return output, hidden, alphas\n"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"9lPdNYu4wbAs","colab_type":"code","colab":{}},"source":["#print(enc)\n","#print(dec)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WYqrDNmxV7Nq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"status":"ok","timestamp":1594381693461,"user_tz":-330,"elapsed":982644,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"6f5a2357-5fcf-49fe-ed02-2a75cef54790"},"source":["vocab_size_src = len(DE.vocab)\n","vocab_size_trg = len(EN.vocab)\n","\n","embedding_size = 300\n","hidden_size = 128\n","n_dropout = 0.1\n","attend_type = 'general'\n","\n","enc = EncoderRNN(vocab_size_src, embedding_size, hidden_size, device)\n","dec = AttentionDecoderRNN(vocab_size_trg, embedding_size, hidden_size, n_dropout, attend_type, device)\n","\n","enc_optim = optim.Adam(enc.parameters())\n","dec_optim = optim.Adam(dec.parameters())\n","    \n","pad_idx = EN.vocab.stoi['<pad>']\n","print('Pad index: ', pad_idx)\n","criterion = nn.NLLLoss(ignore_index=pad_idx)\n","\n","epochs = 20\n","clip = 10\n","\n","epoch_losses = []\n","\n","for epoch in range(epochs):\n","    epoch_loss = 0\n","\n","    for batch in train_iter:\n","        hidden = enc.init_hidden(batch.src.size(1))\n","\n","        max_len_enc = batch.src.size(0)\n","\n","        enc_outputs, hidden = enc(batch.src, hidden)\n","\n","        # enc_outputs is of shape [sequence_len, batch_size, hidden_dim]\n","\n","        # store outputs\n","        max_len_dec = batch.trg.size(0)\n","\n","        outputs = torch.zeros(max_len_dec, batch.trg.size(1), vocab_size_trg, device=device)\n","        input = batch.trg[0]\n","        \n","        for i in range(1, max_len_dec):\n","            output, hidden, alphas = dec(input, hidden, enc_outputs)\n","            outputs[i] = output\n","            input = batch.trg[i]\n","\n","        enc_optim.zero_grad()\n","        dec_optim.zero_grad()\n","\n","        target = torch.tensor(batch.trg[1:], device=device)\n","        loss = criterion(outputs[1:].view(-1, outputs.shape[2]), target.view(-1))\n","        loss.backward()\n","\n","        nn.utils.clip_grad_norm_(enc.parameters(), clip)\n","        nn.utils.clip_grad_norm_(dec.parameters(), clip)\n","\n","        enc_optim.step()\n","        dec_optim.step()\n","\n","        epoch_loss += loss.item()\n","        print('\\rEpoch {} : Loss {:.3f}'.format(epoch, epoch_loss / len(batch)), end=\"\")\n","\n","    print('\\rEpoch {} : Loss {:.3f}'.format(epoch, epoch_loss / len(train_iter)))\n","\n","    epoch_losses.append(epoch_loss / len(train_iter))"],"execution_count":78,"outputs":[{"output_type":"stream","text":["Pad index:  1\n","\rEpoch 0 : Loss 0.265\rEpoch 0 : Loss 0.527"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 0 : Loss 4.000\n","Epoch 1 : Loss 3.087\n","Epoch 2 : Loss 2.617\n","Epoch 3 : Loss 2.273\n","Epoch 4 : Loss 2.039\n","Epoch 5 : Loss 1.864\n","Epoch 6 : Loss 1.723\n","Epoch 7 : Loss 1.613\n","Epoch 8 : Loss 1.521\n","Epoch 9 : Loss 1.445\n","Epoch 10 : Loss 1.377\n","Epoch 11 : Loss 1.321\n","Epoch 12 : Loss 1.265\n","Epoch 13 : Loss 1.220\n","Epoch 14 : Loss 1.174\n","Epoch 15 : Loss 1.137\n","Epoch 16 : Loss 1.099\n","Epoch 17 : Loss 1.066\n","Epoch 18 : Loss 1.038\n","Epoch 19 : Loss 1.010\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sJzP-aiMpj84","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"status":"ok","timestamp":1594380365318,"user_tz":-330,"elapsed":1174,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"cb1c0044-9fe7-42e4-9725-4f1555dbf495"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(epoch_losses)\n","plt.title(\"Training loss\")"],"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'Training loss')"]},"metadata":{"tags":[]},"execution_count":70},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xdZZ3v8c8v92uTNEmTtElaeqe0tIVSoCBUQCyIZS46IzgKioMoeBlxHD1zBh1fM+eMzqijgnJQUFQEHHUQGFBAkItCaaD3ewttkzZN0zTXpk1z+Z0/9koJadKkua2dvb/v12u/svZaz97r19Wdb58++1lrmbsjIiLjX0LYBYiIyMhQoIuIxAgFuohIjFCgi4jECAW6iEiMUKCLiMQIBbrEDDN70sxuGOm2p1nDcjOrGun3FRmMpLALkPhmZi09nmYAbUBn8Pzj7v7AYN/L3a8ajbYi44UCXULl7lndy2a2G/iYuz/Tu52ZJbl7x1jWJjLeaMhFolL30IWZ/YOZHQB+ZGZ5Zva4mdWaWX2wXNrjNX8ws48Fyzea2Utm9h9B2zfN7Kohtj3DzF4ws2Yze8bM7jKznw3yz3FmsK8GM9tkZit7bLvazDYH77vPzD4frC8I/mwNZnbYzF40M/2uyoD0IZFoVgxMBKYCNxP5vP4oeF4OHAXuPMXrzwe2AQXA14F7zcyG0PbnwKtAPvAV4EODKd7MkoHHgKeAScCngAfMbE7Q5F4iw0rZwHzg2WD97UAVUAgUAf8L0DU6ZEAKdIlmXcCX3b3N3Y+6e527/8rdW929GfhX4NJTvH6Pu//A3TuB+4ESIgE56LZmVg6cB9zh7sfd/SXg0UHWfwGQBfxb8NpngceB64Lt7cA8M5vg7vXu/nqP9SXAVHdvd/cXXRddkkFQoEs0q3X3Y91PzCzDzP6fme0xsybgBSDXzBL7ef2B7gV3bw0Ws06z7WTgcI91AJWDrH8yUOnuXT3W7QGmBMt/CVwN7DGz583swmD9vwM7gafM7A0z++Ig9ydxToEu0ax3r/R2YA5wvrtPAC4J1vc3jDISqoGJZpbRY13ZIF+7HyjrNf5dDuwDcPfV7n4tkeGYR4BfBOub3f12d58OrAQ+Z2aXD/PPIXFAgS7jSTaRcfMGM5sIfHm0d+jue4AK4CtmlhL0ot87yJevAlqBL5hZspktD177UPBeHzSzHHdvB5qIDDFhZteY2cxgDL+RyDTOrr53IfIWBbqMJ/8JpAOHgFeA347Rfj8IXAjUAf8CPExkvvwpuftxIgF+FZGavwd82N23Bk0+BOwOho9uCfYDMAt4BmgBXga+5+7PjdifRmKW6bsWkdNjZg8DW9191P+HIHI61EMXGYCZnWdmM8wswcxWANcSGfMWiSo6U1RkYMXAr4nMQ68CPuHua8ItSeRkGnIREYkRGnIREYkRoQ25FBQU+LRp08LavYjIuPTaa68dcvfCvraFFujTpk2joqIirN2LiIxLZranv20achERiRGDDnQzSzSzNWb2eB/bUs3sYTPbaWarzGzaSBYpIiIDO50e+meALf1suwmod/eZwLeArw23MBEROT2DCvTgJgLvAX7YT5NriVxyFOCXwOWnuO60iIiMgsH20P8T+AL9XyBoCsElRYPbhDUSOQnjbczsZjOrMLOK2traIZQrIiL9GTDQzewa4KC7vzbcnbn7Pe6+xN2XFBb2OetGRESGaDA99IuAlcENfB8CLuvjfor7CK4RbWZJQA6RK9OJiMgYGTDQ3f1L7l7q7tOADwDPuvvf9Gr2KHBDsPy+oM2oXFNg24Fm/s8TW2g9rhvAi4j0NOR56Gb21R53ML8XyDezncDngFG7ZVZVfSv3vPAGG/c1jdYuRETGpdM6U9Td/wD8IVi+o8f6Y8D7R7Kw/iwsywVgbWU9S8+YOBa7FBEZF8bdmaIFWamU5qWzrrIx7FJERKLKuAt0iPTS11Y2hF2GiEhUGZeBvrgsl30NRznYfCzsUkREosa4DPTucfT1GnYRETlhXAb6/Mk5JCaYhl1ERHoYl4GenpLInKJs1lUp0EVEuo3LQIe3vhjt6tI9UUVEYBwH+uKyXJqPdfBm3ZGwSxERiQrjNtBPnGC0V8MuIiIwjgN95qQsMlMSNY4uIhIYt4GemGAsKM3RTBcRkcC4DXSARWV5bKlu4lh7Z9iliIiEbpwHeg7tnc7mal15UURknAd6HgDrNOwiIjK+A704J42iCakaRxcRYZwHOsCislz10EVEiIFAX1iWy+66VuqPHA+7FBGRUI37QF8UnGCk+egiEu/GfaAvmJKDGRpHF5G4N+4DPTstmVmTsjSOLiJxb9wHOsDC0siVF9115UURiV8xEeiLynOpb22n8vDRsEsREQlNTAT6wtLIF6NrKutDrkREJDwxEehzirNJS05gne4xKiJxLCYCPTkxgfmTc1irHrqIxLEBA93M0szsVTNbZ2abzOyf+2hzo5nVmtna4PGx0Sm3f4vKctm4v4n2zq6x3rWISFQYTA+9DbjM3RcCi4AVZnZBH+0edvdFweOHI1rlICwsy+V4Rxdbq5vHetciIlFhwED3iJbgaXLwiLr5gd1njK7VGaMiEqcGNYZuZolmthY4CDzt7qv6aPaXZrbezH5pZmX9vM/NZlZhZhW1tbXDKPtkpXnp5Gem6B6jIhK3BhXo7t7p7ouAUmCpmc3v1eQxYJq7nw08Ddzfz/vc4+5L3H1JYWHhcOo+iZlFrryoHrqIxKnTmuXi7g3Ac8CKXuvr3L0tePpD4NyRKe/0LCzLZVdtC03H2sPYvYhIqAYzy6XQzHKD5XTgXcDWXm1KejxdCWwZySIHa1FZLu6woUrz0UUk/gymh14CPGdm64HVRMbQHzezr5rZyqDNp4MpjeuATwM3jk65p9Z9xqiuvCgi8ShpoAbuvh5Y3Mf6O3osfwn40siWdvpyMpKZXpCpQBeRuBQTZ4r2tLBMV14UkfgUc4G+qCyX2uY2qhuPhV2KiMiYirlAX9h9SzoNu4hInIm5QD+zJJuUxASNo4tI3Im5QE9NSuTMyRMU6CISd2Iu0AEWl+WyYV8jnV36YlRE4kdMBvrCshxaj3ey46CuvCgi8SMmA31RWR6ALtQlInElJgN9Wn4GE9KSdKEuEYkrMRnoZsbCslzWqIcuInEkJgMdIl+Mbq9ppvV4R9iliIiMiZgN9IVluXTpyosiEkdiOtABjaOLSNyI2UAvyEqlNC9dJxiJSNyI2UCHyIW61lVqyEVE4kPMB/q+hqMcbNaVF0Uk9sV8oAPqpYtIXIjpQD9rcg6JCcbayvqwSxERGXUxHejpKYnMLc5WD11E4kJMBzpEpi+uq2ygS1deFJEYF/OBvqgsl+a2Dt44dCTsUkRERlVcBDrolnQiEvtiPtBnFGaRlZqkE4xEJObFfKAnJhgLpuToEgAiEvNiPtABFpXnsqW6iWPtnWGXIiIyagYMdDNLM7NXzWydmW0ys3/uo02qmT1sZjvNbJWZTRuNYodqYWku7Z3O5uqmsEsRERk1g+mhtwGXuftCYBGwwswu6NXmJqDe3WcC3wK+NrJlDs/i8sgXo7olnYjEsgED3SNagqfJwaP3pO5rgfuD5V8Cl5uZjViVw1Q0IY3iCWkaRxeRmDaoMXQzSzSztcBB4Gl3X9WryRSgEsDdO4BGIL+P97nZzCrMrKK2tnZ4lZ+mRWW5mukiIjFtUIHu7p3uvggoBZaa2fyh7Mzd73H3Je6+pLCwcChvMWQLy3LZU9dK/ZHjY7pfEZGxclqzXNy9AXgOWNFr0z6gDMDMkoAcoG4kChwp3ScYrdWwi4jEqMHMcik0s9xgOR14F7C1V7NHgRuC5fcBz7p7VF08ZUFpDmY6Y1REYlfSINqUAPebWSKRfwB+4e6Pm9lXgQp3fxS4F/ipme0EDgMfGLWKhygrNYnZk7I1ji4iMWvAQHf39cDiPtbf0WP5GPD+kS1t5C0sy+HpzTW4O1E0CUdEZETExZmi3RaV5VHf2s7ew61hlyIiMuLiKtAXluUAaNhFRGJSXAX6nKJs0pITFOgiEpPiKtCTEhMiV15UoItIDIqrQIfIfPSN+5s43tEVdikiIiMq7gL9nPI8jnd08cedh8IuRURkRMVdoF9+ZhGleen8x1PbdONoEYkpcRfoKUkJ3H7lbDbtb+J/NlSHXY6IyIiJu0AHWLlwCnOKsvnm09tp79RYuojEhrgM9MQE4+/fPYc3Dx3hvyqqwi5HRGRExGWgA1x+5iTOnZrHt3+/naPHda9RERn/4jbQzYx/WDGXmqY27n95d9jliIgMW9wGOsDSMyayfE4h3//DLhqPtoddjojIsMR1oAP8/bvn0Hi0nXte2BV2KSIiwxL3gX7W5BxWLpzMfS/t5mDTsbDLEREZsrgPdIDPvWs27Z1dfPfZnWGXIiIyZAp0YFpBJn99XhkPvrqXvXW6VrqIjE8K9MCnL59FUqLxzae3hV2KiMiQKNADRRPS+MhFZ/CbdfvZvL8p7HJERE6bAr2HWy6ZQXZqEv/xlHrpIjL+KNB7yMlI5hPLZ/Ls1oOs3n047HJERE6LAr2XG5dNY1J2Kl97civuuryuiIwfCvRe0lMS+fTls6jYU89z2w6GXY6IyKAp0Pvw1+eVMTU/g6//VjfBEJHxQ4Heh+TEBG6/cg5bDzTz2Pr9YZcjIjIoAwa6mZWZ2XNmttnMNpnZZ/pos9zMGs1sbfC4Y3TKHTvXLChhXskEvvHUdt1QWkTGhcH00DuA2919HnABcKuZzeuj3Yvuvih4fHVEqwxBQoLx9yvmsPdwKw+v3ht2OSIiAxow0N292t1fD5abgS3AlNEuLBosn13I0jMm8u3f76T1eEfY5YiInNJpjaGb2TRgMbCqj80Xmtk6M3vSzM4agdpCF7kJxhwOtbTxoz/uDrscEZFTGnSgm1kW8Cvgs+7e+9z414Gp7r4Q+C7wSD/vcbOZVZhZRW1t7VBrHlPnTp3IFWdO4u7nd9HQejzsckRE+jWoQDezZCJh/oC7/7r3dndvcveWYPkJINnMCvpod4+7L3H3JYWFhcMsfex8/t1zaGnr4PvP6yYYIhK9BjPLxYB7gS3u/s1+2hQH7TCzpcH71o1koWGaWzyBP180hR//cTcHGnUTDBGJToPpoV8EfAi4rMe0xKvN7BYzuyVo8z5go5mtA74DfMBj7Lz5v3vXbLrc+c6zO8IuRUSkT0kDNXD3lwAboM2dwJ0jVVQ0KpuYwfVLy/nZqr387Tumc0ZBZtgliYi8jc4UPQ23XTaL1KQEvqHL64pIFFKgn4bC7FRuuvgMHl9fzfPbx8csHRGJHwr003TLpTM4s2QCtz7wOtsONIddjojICQr005SZmsR9Ny4hIyWRj/54NQebNetFRKKDAn0ISnLSue/G8zh85Dgfu7+Co8c7wy5JRESBPlTzp+Tw3esWs2FfI599eA2dum66iIRMgT4MV8wr4p/eM4/fbarh357cEnY5IhLnBpyHLqf2kYumsafuCD948U2m5mfyNxdMDbskEYlTCvRhMjP+6Zp57D3cypcf3URpXjrL50wKuywRiUMachkBSYkJfPf6c5hdlM1tP1/D1gO9L0YpIjL6FOgjJCuYzpiZmshHf7Sag02azigiY0uBPoJKctK594bzaDjazk33V+guRyIyphToI6x7OuOm/Y185qG1ms4oImNGgT4KLj+ziDuumcfTm2v4v09oOqOIjA3NchklN150BrvrWvnhS28yNT+DD104LeySRCTGKdBH0T9dM4/K7umMEzN4p6Yzisgo0pDLKEpMML5z3WLOLJnAbQ+8zub9ms4oIqNHgT7KMlOTuPeG88hOS+am+1dTo+mMIjJKFOhjoDgnjXtvXELj0XZuun+1pjOKyKhQoI+RsybncOf1i9m8v4lPP7iWjs6usEsSkRijQB9Dl80t4svvPYtnttRww49epf7I8bBLEpEYokAfYzcsm8bX33c2q9+sZ+VdL+m6LyIyYhToIfirJWU89PELaGvv4i++9yd+u7E67JJEJAYo0ENyTnkej33qYmYXZXPLz17nm09vp0uXCRCRYVCgh6hoQhoP3XwB7z+3lO/8fgcf/9lrtLRpBoyIDI0CPWRpyYl8/X1n85X3zuPZrQf587v+yO5DR8IuS0TGoQED3czKzOw5M9tsZpvM7DN9tDEz+46Z7TSz9WZ2zuiUG5vMjBsvOoOffnQptS1trLzzJZ7fXht2WSIyzgymh94B3O7u84ALgFvNbF6vNlcBs4LHzcD3R7TKOLFsZgGP3XYxk3PT+ciPXuUHL7yBu8bVRWRwBgx0d69299eD5WZgCzClV7NrgZ94xCtArpmVjHi1caBsYga/+sQyVswv5l+f2MLnfrGOY+2dYZclIuPAaY2hm9k0YDGwqtemKUBlj+dVnBz6mNnNZlZhZhW1tRpS6E9mahJ3XX8On79yNo+s3cf7736Z/Q1Hwy5LRKLcoAPdzLKAXwGfdfchnQ3j7ve4+xJ3X1JYWDiUt4gbZsZtl83iBx9awpuHjrDyzpdYvftw2GWJSBQbVKCbWTKRMH/A3X/dR5N9QFmP56XBOhmmK+YV8city8hOS+b6H7zCg6/uDbskEYlSg5nlYsC9wBZ3/2Y/zR4FPhzMdrkAaHR3nf44QmZOyuaRWy9i2YwCvvTrDfzvRzZoXF1ETjKYHvpFwIeAy8xsbfC42sxuMbNbgjZPAG8AO4EfAJ8cnXLjV056MvfdeB4fv3Q6P3tlL1d883l+u7Fas2BE5AQLKxCWLFniFRUVoex7vHt5Vx3//Ngmth5o5qKZ+Xz5vWcxuyg77LJEZAyY2WvuvqSvbTpTdBy6cEY+j3/qYr567Vls3NfEVd9+ka88uonG1vawSxORECnQx6mkxAQ+fOE0nvv8cq5bWsZPXt7NO7/xBx58dS+dusiXSFxSoI9zEzNT+Jc/W8Bjn7qYmYVZfOnXG7j2rpeo0BRHkbijQI8RZ03O4eGPX8B3rlvMoebjvO/ul/nsQ2s40KibUovECwV6DDEzVi6czLOfv5RPXTaTJzYe4LJv/IG7nttJW4emOYrEOgV6DMpISeL2K+fwzN9dysUzC/j3323jym+9wDObazTNUSSGKdBjWHl+Bvd8eAk/vWkpyYkJfOwnFdz4o9Xsqm0JuzQRGQUK9DjwjlmFPPmZd/BP18zj9T31vPtbL/CFX67jDQW7SEzRiUVx5lBLG9/9/Q4eWl1Je2cXVy8o4ZPLZzJv8oSwSxORQTjViUUK9DhV29zGvS+9yc9e2UNLWweXz53EJ985k3On5oVdmoicggJd+tXY2s79L+/mvj++SUNrOxdOz+fWd87kopn5RK7LJiLRRIEuAzrS1sGDr+7lnhfe4GBzGwvLcrl1+QyuOLOIhAQFu0i0UKDLoLV1dPLL16q4+/ldVB4+ypyibD75zhm8Z0EJSYn6Dl0kbAp0OW0dnV08tn4/33tuFzsOtjA1P4NbLp3BX5wzhdSkxLDLE4lbCnQZsq4u56nNNdz13E427GukeEIaf3vJdP5qSSnZaclhlycSdxToMmzuzos7DnHnczt59c3DZKQksnLhZK4/v5yzS3PDLk8kbpwq0JPGuhgZn8yMS2YXcsnsQtZWNvDzVXt4ZO0+HlpdyYIpOVx/fjkrF04mM1UfKZGwqIcuQ9Z4tJ1H1uzj56v2sq2mmazUJK5dNJkPnj9VJyqJjBINuciocnde31vPA6v28j/rq2nr6GJRWS7Xn1/Oe8+eTHqKvkQVGSkKdBkzDa3H+dXr+/j5qj3sqj1CdloSf3lOKdefX677noqMAAW6jDl359U3D/PzV/fy5IYDHO/sYsnUPK4/v5yrF5SQlqxeu8hQKNAlVIePHOeXr1Xy4KuVvHnoCDnpyaw4q5gVC4q5aEYBKUk6YUlksBToEhXcnZd31fGLikqe2XKQlrYOstOSuOLMIlbML+bS2YXquYsMQNMWJSqYGctmFrBsZgFtHZ38cechntxwgKe31PDfa/aRkZLIO+dMYsX8Yt45dxJZmgIpclr0GyOhSE1K5LK5RVw2t4j2zi5WvXGYJzdW87tNNfzPhmpSkhK4ZFYhV80v5oozi8jJ0FmpIgMZcMjFzO4DrgEOuvv8PrYvB34DvBms+rW7f3WgHWvIRfrS2eW8tqc+Eu4bD7C/8RhJCZGe/VXzi7lyXhH5WalhlykSmmGNoZvZJUAL8JNTBPrn3f2a0ylKgS4DcXfWVTXy5MZqfrvxAHvqWkkwWHrGRC6bO4lLZ09idlGWrtsucWXYX4qa2TTgcQW6hMXd2VLdzG+DYZltNc0AFE9I49LgkgQXzyzQ0IzEvLEI9F8BVcB+IuG+qZ/3uRm4GaC8vPzcPXv2DO5PINJLdeNRXtheywvbD/HijlqajnWQYLC4PI9LZhVy6ZxCFkzJIVE355AYM9qBPgHocvcWM7sa+La7zxroPdVDl5HS0dnFuqoGnt9+iOe317K+qgF3yMtI5h2zCoOLihUwKTst7FJFhm1UA72PtruBJe5+6FTtFOgyWg4fOc5LOw/x/LZant9ey6GWNgDmlUzgktmFXDq7kHOm5upGHTIujeo8dDMrBmrc3c1sKZAA1A33fUWGamJmCisXTmblwsl0dTlbDjTxwvZDPL/9ID988Q3ufn4XackJnDdtIhdMz2fZjHwWTMnRLfZk3BvMLJcHgeVAAVADfBlIBnD3u83sNuATQAdwFPicu/9poB2rhy5haGnr4OVddby8q44/7TrE1gORL1ezUpM4/4yJXDgjn2UzCphbnK2bY0tU0qn/Iv2oa2njlTcO86ddh3h5Vx1vHDoCRMbfL5yRz4UzClg2I5/pBZmaHilRQaf+i/QjPyuV95xdwnvOLgEis2civfc6/rTzEE9sOADApOxUlgW99wtn5FOal66Al6ijHrpIP9ydvYdbI+G+q46Xdx3iUMtxAIompLKoLJfF5XksLstlQWkOGSnqH8noUw9dZAjMjKn5mUzNz+S6peW4OzsOtvDyrjrW7K1nTWUDv9tUA0BigjG3OPutkC/P5Yz8TI3Dy5hSD11kGOpa2lhX1cCavZHHusoGmts6AMhJTw4CPpdFZZFHbkZKyBXLeKcvRUXGSFeXs6u2JRLwlfWs2dvA9ppmuoJfs+mFmSwuy+Ps0hwWlOYwr2SCrgEvp0WBLhKilrYO1lc1sLbyrZ5898lOiQnGrElZkYCfksOC0lzmFmcr5KVfGkMXCVFWahLLZhSwbEYBEPmy9UDTMTZUNbJhXyPrqxp5ZstBflFRBUBSgjG7KJuzS3OYPyWHs0tzmFOcrTNbZUDqoYtEAXdnf+MxNlQ1nAj5DfsaaWhtByA50ZhTnM2CKbksmJLDvMkTmFOUTXqKQj7eaMhFZBxyd6rqj7JhXyTcN1Q1sr6qgaZjkS9dzeCM/EzmlmRzZvEE5pZMYG5xtubIxzgNuYiMQ2ZG2cQMyiZmcPWCyIlP7k7l4aNsrm5i64EmtlY3s3l/04kToACyU5OYW5LN3OIJkbAvifTmM3WP1pinv2GRccTMKM/PoDw/gxXzi0+sP9LWwbaaZrZWN7MlCPtH1uyj+ZWOE22m5mcEPflsZhdlM2tSFlPzM0lJ0kXJYoUCXSQGZKYmcU55HueU551Y5+7sazjKlupmtlY3sfVAJOx/t/kA3SOtSQnG1PwMZk3KZlZRFjMnRR4zCrM002YcUqCLxCgzozQvg9K8DN41r+jE+qPHO9lV28LOg5HHjoPNbD/YzNNbaugMJsybQfnEDGZNymLGpKxI4AfLWRq6iVr6mxGJM+kpicyfEpkS2VNbRye7D7Wy42BzEPQt7Kxp4fnttbR3vjV5YkpuOrOKsphTFBm6mVOczcxJ6tFHAwW6iACQmpTInOJIQPfU0dnFnsOtJ3r022ua2V7Twp921nG8swuABINp+ZnMLspmdnE2c4qymVOcxbT8TN04ZAwp0EXklJISE5hRGBlXf/dZb63v6Oxid10r22ua2XYg8the08xTmw+cuNRBSmIC0wszmVMc9OaDHv3k3HTdwHsUKNBFZEiSEhNOfInaPa0S4Fh754me/LaaZrYfaKZidz2/Wbv/RJvkRGNybjqleemU5mZEfk5MpzQvg7K8DCZlp+pKlUOgQBeREZWW3PcYfdOxdnbURIJ+7+FWquqPUlXfyrPbDlLb3Pa2timJCUzOTQu+1I0Ef9nE7uUMCrMU+H1RoIvImJiQlsy5U/M4d2reSduOtXeeCPjIz8hyZf1RntlSc+LGIt1SkxKYmp9B+cRMpuVnMDU/g6n5mUzLz2Ryblrcjtsr0EUkdGnJiSeGb/py9Hgn+xoiAV91uJU9da3sOdzKnrojvLSzlmPtXSfaJiUYpXnplOdHwr58YgbT8jOZmh856zaWZ+Mo0EUk6qWnJDJzUjYzJ2WftK2ryznY3MaeuiNB0Ac/61pZs7ee5mNvnS1rBsUT0ijrMZTTPawzJS+dkpz0cX3mrAJdRMa1hASjOCeN4pw0zp+e/7Zt7k5Da/uJ3vyeulZ21x2hqv4oq948zCNrj56YkQNvBX530E/JfXvol+SmRfVljBXoIhKzzIy8zBTyMlNYVJZ70vb2zi4ONB7rc/x+9e7DPNp47MTZs5H3g0nZqScC/q2efgZlE8Pv4SvQRSRuJScmnLiiJeSftL2js4sDTcdOBP2++qNU1rdSVd/Ka3vqeXx99UmB393D7xn23bN0inPSSB7FL2wV6CIi/UhKTDhxPZy+dAd+5eG39/Ar61v7HNJJMCjJSefGZdP420umj3y9AzUws/uAa4CD7j6/j+0GfBu4GmgFbnT310e6UBGRaPP2wD+5h9/e2UV1w7EeYR+ZqTNpQuro1DOINj8G7gR+0s/2q4BZweN84PvBTxGRuJacmHDi+vVjYcDBHHd/ATh8iibXAj/xiFeAXDMrOUV7EREZBSMxOj8FqOzxvCpYdxIzu9nMKsysora2dgR2LSIi3cZ0fo273+PuS9x9SWFh4VjuWkQk5o1EoO8Dyno8Lw3WiYjIGBqJQH8U+LBFXAA0unv1CLyviIichsFMW3wQWA4UmFkV8GUgGcDd7waeIFzU974AAAUySURBVDJlcSeRaYsfGa1iRUSkfwMGurtfN8B2B24dsYpERGRIxu9lxURE5G0s0sEOYcdmtcCeIb68ADg0guWMtGivD6K/RtU3PKpveKK5vqnu3uc0wdACfTjMrMLdl4RdR3+ivT6I/hpV3/CovuGJ9vr6oyEXEZEYoUAXEYkR4zXQ7wm7gAFEe30Q/TWqvuFRfcMT7fX1aVyOoYuIyMnGaw9dRER6UaCLiMSIqA50M1thZtvMbKeZfbGP7alm9nCwfZWZTRvD2srM7Dkz22xmm8zsM320WW5mjWa2NnjcMVb1BfvfbWYbgn1X9LHdzOw7wfFbb2bnjGFtc3ocl7Vm1mRmn+3VZsyPn5ndZ2YHzWxjj3UTzexpM9sR/Mzr57U3BG12mNkNY1jfv5vZ1uDv8L/N7OS7ITPw52EU6/uKme3r8fd4dT+vPeXv+yjW93CP2nab2dp+Xjvqx2/Y3D0qH0AisAuYDqQA64B5vdp8Erg7WP4A8PAY1lcCnBMsZwPb+6hvOfB4iMdwN1Bwiu1XA08CBlwArArx7/oAkRMmQj1+wCXAOcDGHuu+DnwxWP4i8LU+XjcReCP4mRcs541RfVcCScHy1/qqbzCfh1Gs7yvA5wfxGTjl7/to1ddr+zeAO8I6fsN9RHMPfSmw093fcPfjwENE7o7U07XA/cHyL4HLg3ucjjp3r/bg3qnu3gxsoZ8be0SxaLnb1OXALncf6pnDI8b7vkNXz8/Z/cCf9fHSdwNPu/thd68HngZWjEV97v6Uu3cET18hcgnrUPRz/AZjML/vw3aq+oLs+CvgwZHe71iJ5kAfzJ2QTrQJPtCN9HWn1lEWDPUsBlb1sflCM1tnZk+a2VljWhg48JSZvWZmN/exfdB3mxplH6D/X6Iwj1+3In/rktAHgKI+2kTLsfwokf919WWgz8Noui0YErqvnyGraDh+7wBq3H1HP9vDPH6DEs2BPi6YWRbwK+Cz7t7Ua/PrRIYRFgLfBR4Z4/IudvdziNzI+1Yzu2SM9z8gM0sBVgL/1cfmsI/fSTzyf++onOtrZv8IdAAP9NMkrM/D94EZwCKgmsiwRjS6jlP3zqP+9ymaA30wd0I60cbMkoAcoG5MqovsM5lImD/g7r/uvd3dm9y9JVh+Akg2s4Kxqs/d9wU/DwL/TeS/tT1Fw92mrgJed/ea3hvCPn491HQPRQU/D/bRJtRjaWY3AtcAHwz+0TnJID4Po8Lda9y90927gB/0s9+wj18S8BfAw/21Cev4nY5oDvTVwCwzOyPoxX2AyN2RenoU6J5N8D7g2f4+zCMtGG+7F9ji7t/sp01x95i+mS0lcrzH5B8cM8s0s+zuZSJfnG3s1Swa7jbVb68ozOPXS8/P2Q3Ab/po8zvgSjPLC4YUrgzWjTozWwF8AVjp7q39tBnM52G06uv5vcyf97Pfwfy+j6YrgK3uXtXXxjCP32kJ+1vZUz2IzMLYTuTb738M1n2VyAcXII3If9V3Aq8C08ewtouJ/Nd7PbA2eFwN3ALcErS5DdhE5Bv7V4BlY1jf9GC/64Iauo9fz/oMuCs4vhuAJWP895tJJKBzeqwL9fgR+celGmgnMo57E5HvZX4P7ACeASYGbZcAP+zx2o8Gn8WdwEfGsL6dRMafuz+H3TO/JgNPnOrzMEb1/TT4fK0nEtIlvesLnp/0+z4W9QXrf9z9uevRdsyP33AfOvVfRCRGRPOQi4iInAYFuohIjFCgi4jECAW6iEiMUKCLiMQIBbqISIxQoIuIxIj/D48xmrPKdU/gAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"HiXYRMKkqiyi","colab_type":"code","colab":{}},"source":["import matplotlib.ticker as ticker\n","import matplotlib.pyplot as plt\n","\n","def show_attention(input_sentence, output_words, attentions):\n","    # Set up figure with colorbar\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(np.array(attentions))\n","    fig.colorbar(cax)\n","\n","    # # Set up axes\n","    ax.set_xticklabels([''] + input_sentence +\n","                       ['<EOS>'], rotation=90)\n","    ax.set_yticklabels([''] + output_words)\n","\n","    # # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQ6RHiXNPeEY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1594376362225,"user_tz":-330,"elapsed":1276,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"68c3b694-36b3-4421-c31b-9c65074ee61e"},"source":["#### Using concat\n","\n","sos_idx = EN.vocab.stoi['<sos>']\n","eos_idx = EN.vocab.stoi['<eos>']\n","\n","batch = next(iter(valid_iter))\n","\n","for i in range(5):\n","    with torch.no_grad():\n","        encoder_input = batch.src[:, i].unsqueeze(1)\n","        hidden = enc.init_hidden(1)\n","\n","        encoded = []\n","        for ip in encoder_input:\n","            encoded.append(DE.vocab.itos[ip.item()])\n","\n","        enc_outputs, hidden = enc(encoder_input, hidden)\n","\n","        max_len_enc = batch.src.size(0)\n","        max_len_dec = batch.trg.size(0)\n","        decoder_input = torch.tensor([sos_idx], device=device)\n","        decoder_attentions = torch.zeros(max_len_dec*2, max_len_enc)\n","\n","        decoded = []\n","        decoded.append(EN.vocab.itos[sos_idx])\n","\n","        true = [EN.vocab.itos[w] for w in batch.trg[:, i].unsqueeze(1)]\n","\n","        k = 0\n","        while True:\n","            output, hidden, alphas = dec(decoder_input, hidden, enc_outputs)\n","            topv, topi = output.topk(1)\n","            topi = topi.squeeze(1)\n","            decoder_input = topi.detach()\n","\n","            decoder_attentions[k] = alphas\n","            k += 1\n","            \n","            decoded.append(EN.vocab.itos[decoder_input.item()])\n","            if decoder_input.item() == eos_idx:\n","                break\n","\n","        print(encoded)\n","        print(decoded)\n","        print(true)\n","        print()\n","\n","        #show_attention(encoded, decoded, decoder_attentions)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['<sos>', 'Ein', 'Kind', 'sitzt', 'auf', 'einer', '<unk>', '.', '<eos>']\n","['<sos>', 'A', 'child', 'sits', 'on', 'a', 'wooden', 'workbench', '.', '<eos>']\n","['<sos>', 'A', 'child', 'sitting', 'on', 'a', 'rock', 'formation', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n","['<sos>', 'Zwei', 'Frauen', 'lÃ¤cheln', 'bei', 'einer', 'Veranstaltung', '.', '<eos>']\n","['<sos>', 'Two', 'women', 'are', 'smiling', 'at', 'an', 'event', '.', '<eos>']\n","['<sos>', 'Two', 'women', 'are', 'smiling', 'at', 'an', 'event', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n","['<sos>', 'Zwei', 'Pudel', 'rennen', 'durch', 'den', 'Schnee', '.', '<eos>']\n","['<sos>', 'Two', 'poodles', 'running', 'through', 'the', 'snow', '.', '<eos>']\n","['<sos>', 'Two', 'poodles', 'are', 'running', 'through', 'the', 'snow', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n","['<sos>', '<unk>', '<unk>', 'tagsÃ¼ber', 'ihre', '<unk>', '.', '<eos>', '<pad>']\n","['<sos>', '<unk>', '<unk>', 'their', '<unk>', '<unk>', 'their', 'way', 'show', '.', '<eos>']\n","['<sos>', '<unk>', 'are', 'performing', 'their', '<unk>', 'during', 'the', 'day', '.', '<eos>', '<pad>', '<pad>']\n","\n","['<sos>', 'Drei', 'Hunde', 'spielen', 'im', 'Wasser', '.', '<eos>', '<pad>']\n","['<sos>', 'Three', 'dogs', 'play', 'in', 'the', 'water', '.', '<eos>']\n","['<sos>', 'Three', 'dogs', 'are', 'playing', 'in', 'the', 'water', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ls0tkuHza2di","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1594380662411,"user_tz":-330,"elapsed":1295,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"f93526ad-5357-4e90-ce66-e940fc7c8a52"},"source":["#### Using dot\n","\n","sos_idx = EN.vocab.stoi['<sos>']\n","eos_idx = EN.vocab.stoi['<eos>']\n","\n","batch = next(iter(valid_iter))\n","\n","for i in range(5):\n","    with torch.no_grad():\n","        encoder_input = batch.src[:, i].unsqueeze(1)\n","        hidden = enc.init_hidden(1)\n","\n","        encoded = []\n","        for ip in encoder_input:\n","            encoded.append(DE.vocab.itos[ip.item()])\n","\n","        enc_outputs, hidden = enc(encoder_input, hidden)\n","\n","        max_len_enc = batch.src.size(0)\n","        max_len_dec = batch.trg.size(0)\n","        decoder_input = torch.tensor([sos_idx], device=device)\n","        decoder_attentions = torch.zeros(max_len_dec*2, max_len_enc)\n","\n","        decoded = []\n","        decoded.append(EN.vocab.itos[sos_idx])\n","\n","        true = [EN.vocab.itos[w] for w in batch.trg[:, i].unsqueeze(1)]\n","\n","        k = 0\n","        while True:\n","            output, hidden, alphas = dec(decoder_input, hidden, enc_outputs)\n","            topv, topi = output.topk(1)\n","            topi = topi.squeeze(1)\n","            decoder_input = topi.detach()\n","\n","            decoder_attentions[k] = alphas\n","            k += 1\n","            \n","            decoded.append(EN.vocab.itos[decoder_input.item()])\n","            if decoder_input.item() == eos_idx:\n","                break\n","\n","        print(encoded)\n","        print(decoded)\n","        print(true)\n","        print()\n","\n","        #show_attention(encoded, decoded, decoder_attentions)"],"execution_count":76,"outputs":[{"output_type":"stream","text":["['<sos>', 'Ein', 'Kind', 'sitzt', 'auf', 'einer', '<unk>', '.', '<eos>']\n","['<sos>', 'A', 'child', 'sits', 'on', 'a', '<unk>', 'wall', '.', '<eos>']\n","['<sos>', 'A', 'child', 'sitting', 'on', 'a', 'rock', 'formation', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n","['<sos>', 'Zwei', 'Frauen', 'lÃ¤cheln', 'bei', 'einer', 'Veranstaltung', '.', '<eos>']\n","['<sos>', 'Two', 'women', 'are', 'smiling', 'at', 'an', 'event', '.', '<eos>']\n","['<sos>', 'Two', 'women', 'are', 'smiling', 'at', 'an', 'event', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n","['<sos>', 'Zwei', 'Pudel', 'rennen', 'durch', 'den', 'Schnee', '.', '<eos>']\n","['<sos>', 'Two', 'poodles', 'are', 'running', 'through', 'the', 'snow', '.', '<eos>']\n","['<sos>', 'Two', 'poodles', 'are', 'running', 'through', 'the', 'snow', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n","['<sos>', '<unk>', '<unk>', 'tagsÃ¼ber', 'ihre', '<unk>', '.', '<eos>', '<pad>']\n","['<sos>', '<unk>', '<unk>', '<unk>', 'their', '<unk>', 'for', 'a', '<unk>', '.', '<eos>']\n","['<sos>', '<unk>', 'are', 'performing', 'their', '<unk>', 'during', 'the', 'day', '.', '<eos>', '<pad>', '<pad>']\n","\n","['<sos>', 'Drei', 'Hunde', 'spielen', 'im', 'Wasser', '.', '<eos>', '<pad>']\n","['<sos>', 'Three', 'dogs', 'are', 'playing', 'in', 'the', 'water', '.', '<eos>']\n","['<sos>', 'Three', 'dogs', 'are', 'playing', 'in', 'the', 'water', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-A7YYNhifyLq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1594381734173,"user_tz":-330,"elapsed":1098,"user":{"displayName":"Amanda Dsouza","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkffm5w1hHnPwIkHy2bn2_f_5G1DCCs7UyuQjVWA=s64","userId":"07364365218528039773"}},"outputId":"cc5f5deb-c3f4-4d96-c08b-4354106ab656"},"source":["#### Using general\n","\n","sos_idx = EN.vocab.stoi['<sos>']\n","eos_idx = EN.vocab.stoi['<eos>']\n","\n","batch = next(iter(valid_iter))\n","\n","for i in range(5):\n","    with torch.no_grad():\n","        encoder_input = batch.src[:, i].unsqueeze(1)\n","        hidden = enc.init_hidden(1)\n","\n","        encoded = []\n","        for ip in encoder_input:\n","            encoded.append(DE.vocab.itos[ip.item()])\n","\n","        enc_outputs, hidden = enc(encoder_input, hidden)\n","\n","        max_len_enc = batch.src.size(0)\n","        max_len_dec = batch.trg.size(0)\n","        decoder_input = torch.tensor([sos_idx], device=device)\n","        decoder_attentions = torch.zeros(max_len_dec*2, max_len_enc)\n","\n","        decoded = []\n","        decoded.append(EN.vocab.itos[sos_idx])\n","\n","        true = [EN.vocab.itos[w] for w in batch.trg[:, i].unsqueeze(1)]\n","\n","        k = 0\n","        while True:\n","            output, hidden, alphas = dec(decoder_input, hidden, enc_outputs)\n","            topv, topi = output.topk(1)\n","            topi = topi.squeeze(1)\n","            decoder_input = topi.detach()\n","\n","            decoder_attentions[k] = alphas\n","            k += 1\n","            \n","            decoded.append(EN.vocab.itos[decoder_input.item()])\n","            if decoder_input.item() == eos_idx:\n","                break\n","\n","        print(encoded)\n","        print(decoded)\n","        print(true)\n","        print()\n","\n","        #show_attention(encoded, decoded, decoder_attentions)"],"execution_count":79,"outputs":[{"output_type":"stream","text":["['<sos>', 'Ein', 'Kind', 'sitzt', 'auf', 'einer', '<unk>', '.', '<eos>']\n","['<sos>', 'A', 'child', 'is', 'sitting', 'on', 'a', '<unk>', '.', '<eos>']\n","['<sos>', 'A', 'child', 'sitting', 'on', 'a', 'rock', 'formation', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n","['<sos>', 'Zwei', 'Frauen', 'lÃ¤cheln', 'bei', 'einer', 'Veranstaltung', '.', '<eos>']\n","['<sos>', 'Two', 'women', 'smiling', 'at', 'an', 'event', '.', '<eos>']\n","['<sos>', 'Two', 'women', 'are', 'smiling', 'at', 'an', 'event', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n","['<sos>', 'Zwei', 'Pudel', 'rennen', 'durch', 'den', 'Schnee', '.', '<eos>']\n","['<sos>', 'Two', 'poodles', 'are', 'running', 'through', 'the', 'snow', '.', '<eos>']\n","['<sos>', 'Two', 'poodles', 'are', 'running', 'through', 'the', 'snow', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n","['<sos>', '<unk>', '<unk>', 'tagsÃ¼ber', 'ihre', '<unk>', '.', '<eos>', '<pad>']\n","['<sos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n","['<sos>', '<unk>', 'are', 'performing', 'their', '<unk>', 'during', 'the', 'day', '.', '<eos>', '<pad>', '<pad>']\n","\n","['<sos>', 'Drei', 'Hunde', 'spielen', 'im', 'Wasser', '.', '<eos>', '<pad>']\n","['<sos>', 'Three', 'dogs', 'are', 'playing', 'in', 'the', 'water', '.', '<eos>']\n","['<sos>', 'Three', 'dogs', 'are', 'playing', 'in', 'the', 'water', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n","\n"],"name":"stdout"}]}]}